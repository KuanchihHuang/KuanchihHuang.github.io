<html>
<head>
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
	<title>Kuan-Chih Huang </title>
	<meta content="Kuan-Chih Huang" name="keywords" />
    <meta name="keywords" content="Kuan-Chih Huang, 黃冠智, kuan-chih, kuanchih huang">
    <link rel="stylesheet" href="./style.css">
    <link rel="stylesheet" href="./Font-Awesome-5.15.4/css/all.min.css">
    <link rel="stylesheet" href="./academicons-1.9.1/css/academicons.css">
</head>

<body>
    <div style="margin-bottom: 0em; border: 0px solid #ddd; background-color: #fff; padding: 2em; height: 180px;">
        <div style="margin: 0px auto; width: 100%;">
            <img title="Kuan-Chih Huang" style="float: left; padding-left: .1em; height: 190px;" src="imgs/kuanchih.jpg" alt="KUANCHIH" />
            <div style="padding-left: 13.5em; vertical-align: top; height: 150px;"><span style="line-height: 180%; font-size: 20pt; font-weight: 900; color: 4a4a4a;">Kuan-Chih Huang</span><br />
                <span style="font-size: 12pt">I am currently a first-year EECS Ph.D. student at University of California, Merced, advised by <a href=https://faculty.ucmerced.edu/mhyang/>Prof. Ming-Hsuan Yang</a> and <a href=https://sites.google.com/site/yihsuantsai/>Dr. Yi-Hsuan Tsai</a>. Previously, I was a full-time research assistant, working with <a href=https://winstonhsu.info/> Prof. Winston H. Hsu</a>. I received my B.S. degree and M.S. degree in Physics and Electrical Engineering from National Taiwan University, respectively. My current research interests are world model and 3D vision.</span><br/>
            </div>
<!--a href="mailto:s928001810@gmail.com" style="padding-left: 1.5em; font-size: 18pt"><i class="fas fa-envelope"></i><--/a-->
            <a href='https://scholar.google.com/citations?user=9tPZXEcAAAAJ&hl=zh-TW' target="_blank" style="padding-left: 1.5em; font-size: 19pt"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/kuanchihHuang" target="_blank" style="font-size: 17pt" title="GitHub"><i class="fab fa-github"></i></a>
            <a style="padding-left:0.5em; color:4a4a4a; font-size: 12pt"><b>Email: s928001810 [at] gmail.com / kuanchih1huang [at] gmail.com</b></a><br>
            <a style="padding-left:2.5em; color:FF0000; font-size: 12pt">Actively looking for 2024 summer intern position about 3D computer vision. </a><br>
        </div>
    </div>

    <a name="pub"></a>
    <div style="clear: both;">
        <div class="section" style="padding-left: 1em; padding-top: 1em">
            <h2>Publications</h2>

            <div class="paper" id="09"><img class="paper" src="imgs/ptt2023.png" />
                <div>
                    <a><b>PTT: Point-Trajectory Transformer for Efficient Temporal 3D Object Detection</b></a><br/>
                    <i class="fas fa-user" style="color: #4a4a4a;"></i>
                    <b>Kuan-Chih Huang</b>, Weijie Lyu, Ming-Hsuan Yang, Yi-Hsuan Tsai<br />
                    <i class="fas fa-book" style="color: #4a4a4a;"></i>
                    <i>IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2024 </i><br />
                    <a href="https://arxiv.org/abs/2312.08371" target="_blank"><i class="far fa-file-pdf" ></i>
                        [Paper]</a>
                    <a href="https://github.com/kuanchihhuang/PTT"><i class="fab fa-github" ></i>
                        [Code]</a>
                    <br />
                </div>
                <div class="spanner"></div>
            </div>



            <div class="paper" id="08"><img class="paper" src="imgs/w3d2023.png" />
                <div>
                    <a><b>Weakly Supervised 3D Object Detection via Multi-Level Visual Guidance</b></a><br/>
                    <i class="fas fa-user" style="color: #4a4a4a;"></i>
                    <b>Kuan-Chih Huang</b>, Yi-Hsuan Tsai, Ming-Hsuan Yang<br />
                    <i class="fas fa-book" style="color: #4a4a4a;"></i>
                    <i>Arxiv <b>(Arxiv)</b>, 2023 </i><br />
                    <a href="https://arxiv.org/abs/2312.07530" target="_blank"><i class="far fa-file-pdf" ></i>
                        [Paper]</a>
                    <a href="https://github.com/kuanchihhuang/VG-W3D"><i class="fab fa-github" ></i>
                        [Code]</a>
                    <br />
                </div>
                <div class="spanner"></div>
            </div>


            <div class="paper" id="07"><img class="paper" src="imgs/iccv2023.png" />
                <div>
                    <a><b>Delving into Motion-Aware Matching for Monocular 3D Object Tracking</b></a><br/>
                    <i class="fas fa-user" style="color: #4a4a4a;"></i>
                    <b>Kuan-Chih Huang</b>, Ming-Hsuan Yang, Yi-Hsuan Tsai<br />
                    <i class="fas fa-book" style="color: #4a4a4a;"></i>
                    <i>International Conference on Computer Vision <b>(ICCV)</b>, 2023 </i><br />
                    <a href="https://arxiv.org/abs/2308.11607" target="_blank"><i class="far fa-file-pdf" ></i>
                        [Paper]</a>
                    <a href="https://github.com/kuanchihhuang/MoMA-M3T"><i class="fab fa-github" ></i>
                        [Code]</a>
                    <br />
                </div>
                <div class="spanner"></div>
            </div>

            <div class="paper" id="05"><img class="paper" src="imgs/CVPR2022.png" />
                <div>
                    <a><b>MonoDTR: Monocular 3D Object Detection with Depth-Aware Transformer</b></a><br/>
                    <i class="fas fa-user" style="color: #4a4a4a;"></i>
                    <b>Kuan-Chih Huang</b>, Tsung-Han Wu, Hung-Ting Su, Winston H. Hsu<br />
                    <i class="fas fa-book" style="color: #4a4a4a;"></i>
                    <i>IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b>, 2022 </i><br />
                    <a href="https://arxiv.org/abs/2203.10981" target="_blank"><i class="far fa-file-pdf" ></i>
                        [Paper]</a>
                    <a href="https://github.com/KuanchihHuang/MonoDTR"><i class="fab fa-github" ></i>
                        [Code]</a>
                    <br />
                </div>
                <div class="spanner"></div>
            </div>
            
            <div class="paper" id="06"><img class="paper" src="imgs/eccv2022.png" />
                <div>
                    <a><b>D2ADA: Dynamic Density-aware Active Domain Adaptation for Semantic Segmentation</b></a><br/>
                    <i class="fas fa-user" style="color: #4a4a4a;"></i>
                    Tsung-Han Wu, Yi-Syuan Liou, Shao-Ji Yuan, Hsin-Ying Lee, Tung-I Chen, <b>Kuan-Chih Huang</b>, Winston H Hsu<br />
                    <i class="fas fa-book" style="color: #4a4a4a;"></i>
                    <i>European Conference on Computer Vision <b>(ECCV)</b>, 2022 </i><br />
                    <a href="https://arxiv.org/abs/2202.06484" target="_blank"><i class="far fa-file-pdf" ></i>
                        [Paper]</a>
                    <a href="https://github.com/tsunghan-wu/D2ADA"><i class="fab fa-github" ></i>
                        [Code]</a>
                    <br />
                </div>
                <div class="spanner"></div>
            </div>
            
            <div class="paper" id="04"><img class="paper" src="imgs/bmvc_2021.jpg" />
                <div>
                    <a><b>Multi-Stream Attention Learning for Monocular Vehicle Velocity and Inter-Vehicle Distance Estimation</b></a><br/>
                    <i class="fas fa-user" style="color: #4a4a4a;"></i>
                    <b>Kuan-Chih Huang</b>, Yu-Kai Huang, Winston H. Hsu<br />
                    <i class="fas fa-book" style="color: #4a4a4a;"></i>
                    <i>British Machine Vision Conference <b>(BMVC)</b>, 2021 </i><br />
                    <a href="https://arxiv.org/abs/2110.11608" target="_blank"><i class="far fa-file-pdf" ></i>
                        [Paper]</a>
                    <br />
                </div>
                <div class="spanner"></div>
            </div>

            <div class="paper" id="03"><img class="paper" src="imgs/iros2021_masnet.jpg" />
                <div>
                    <a><b>Multi-Scale Aggregation with Self-Attention Network for Modeling Electrical Motor Dynamics</b></a><br />
                    <span style="color: #4a4a4a;;">
                        <i class="fas fa-user"></i>
                    </span>
                    <b>Kuan-Chih Huang*</b>, Hao-Hsiang Yang*, Wei-Ting Chen<br />
                    <i class="fas fa-book" style="color: #4a4a4a;"></i>
                    <i > IEEE/RSJ Conference on Intelligent Robots and Systems <b>(IROS)</b>, 2021 </i><br />

                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9636717" target="_blank"><i class="far fa-file-pdf" ></i>
                        [Paper]
                    </a>
                    <br/>
                </div>
                <div class="spanner"></div>
            </div>

            <div class="paper" id="02"><img class="paper" src="imgs/MICCAI2021.png" />
                <div>
                    <a><b>Leveraging Auxiliary Information from EMR for Weakly Supervised Pulmonary Nodule Detection</b></a><br />
                    <span style="color: #4a4a4a;">
                        <i class="fas fa-user"></i>
                    </span>
                        Hao-Hsiang Yang, Fu-En Wang, Cheng Sun, <b>Kuan-Chih Huang</b>, Hung-Wei Chen, Yi Chen, Hung-Chih Chen, 
                        Chun-Yu Liao, Shih-Hsuan Kao, Yu-Chiang Frank Wang, Chou-Jin Lan <br />
                    <span style="color: #4a4a4a;">
                        <i class="fas fa-book"></i>
                    </span>
                    <i> International Conference on Medical Image Computing and Computer Assisted Intervention <b>(MICCAI)</b>, 2021</i> <br />
                    <a href='https://link.springer.com/chapter/10.1007%2F978-3-030-87234-2_24' target="_blank">
                        <i class="far fa-file-pdf" ></i>
                        [Paper]
                    </a> 
                    <br/>
                </div>
                <div class="spanner"></div>
            </div>

            <div class="paper" id="01"><img class="paper" src="imgs/icra2021_affnet.png" />
            <div>
                <a><b>LAFFNet: A Lightweight Adaptive Feature Fusion Network for Underwater Image Enhancement</b></a><br />
                    <i class="fas fa-user" style="color: #4a4a4a;"></i>
                    Hao-Hsiang Yang, <b>Kuan-Chih Huang</b>, Wei-Ting Chen<br />
                <i class="fas fa-book" style="color: #4a4a4a;"></i>
                <i> IEEE International Conference on Robotics and Automation <b>(ICRA)</b>, 2021</i> <br />
                    <a href="https://arxiv.org/abs/2105.01299" target="_blank">
                        <i class="far fa-file-pdf" ></i>
                        [Paper]
                    </a>
                </div>
            <div class="spanner"></div>
        </div>
    </div>
</div>


    <a name="news"></a>
    <div style="clear: both;">
        <div class="section" style="padding-left: 0.8em; padding-top: 1em">
            <h2>Professional Activities</h2>
            <div class="paper" style="font-size: 12pt">
                <ul>
                    <li> Conference Reviewer: CVPR, ICCV, ECCV, AAAI, WACV.</li>
                    <li> Journal Reviewer: TPAMI, IJCV.</li>
                </ul>
            </div>
        </div>
    </div>


<div style="text-align: right; font-style: italic; font-size: 13">
    Last Updated: <script language="JavaScript"> document.write(document.lastModified)</script></p>
</div>

</body>
</html>
